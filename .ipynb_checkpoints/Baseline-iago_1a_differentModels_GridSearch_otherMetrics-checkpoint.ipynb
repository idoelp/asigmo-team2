{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First things first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_humor  humor_rating  \\\n",
       "0  TENNESSEE: We're the best state. Nobody even c...         1          2.42   \n",
       "1  A man inserted an advertisement in the classif...         1          2.50   \n",
       "2  How many men does it take to open a can of bee...         1          1.95   \n",
       "3  Told my mom I hit 1200 Twitter followers. She ...         1          2.11   \n",
       "4  Roses are dead. Love is fake. Weddings are bas...         1          2.78   \n",
       "\n",
       "   humor_controversy  offense_rating  \n",
       "0                1.0             0.2  \n",
       "1                1.0             1.1  \n",
       "2                0.0             2.4  \n",
       "3                1.0             0.0  \n",
       "4                0.0             0.1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv').drop(columns = 'id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['text']], df['is_humor'], test_size = 0.2, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Two meth heads start a relationship, is that c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "count                                                6400\n",
       "unique                                               6400\n",
       "top     Two meth heads start a relationship, is that c...\n",
       "freq                                                    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of positives is  0.61\n",
      "% of negatives is  0.39\n"
     ]
    }
   ],
   "source": [
    "total = len(y_train)\n",
    "print('% of positives is ', round(y_train.sum()/total, 2)) #'% of positives is {:.2f}'.format(y_train.sum()/total)\n",
    "print('% of negatives is ', round((total - y_train.sum())/total, 2)) #'% of negatives is {:.2f}'.format((total - y_train.sum())/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2466.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        3934.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text, stemmer):\n",
    "    return(' '.join([stemmer.stem(w) for w in word_tokenize(text)]))\n",
    "\n",
    "def count_words(input):\n",
    "    \"\"\" Returns number of occurences of characters specified in char \"\"\"     \n",
    "    return len(input.split())\n",
    "\n",
    "def remove_punctuation(s_input, include_char = None):\n",
    "    \"\"\" Returns input string without punctuation \"\"\"\n",
    "    import string as String\n",
    "    punct = String.punctuation\n",
    "    \n",
    "    if not include_char is None:\n",
    "        index = String.punctuation.index(include_char)\n",
    "        punct = String.punctuation[:index] + String.punctuation[(index + 1):]\n",
    "        \n",
    "    punct += '\\n'\n",
    "        \n",
    "    translator = str.maketrans(punct, ' '*len(punct))\n",
    "    \n",
    "    return s_input.translate(translator)\n",
    "\n",
    "def remove_stopwords(text, use_stopwords = None, df = True, exclude_number = True):\n",
    "    \"\"\" Returns input string removing stopwords from it. \"\"\"\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    if use_stopwords is None:\n",
    "        use_stopwords = set(stopwords.words(\"english\"))\n",
    "        \n",
    "    if df:\n",
    "        new_text = word_tokenize(text)\n",
    "        if exclude_number:\n",
    "            new_text = [word for word in new_text if not word.isnumeric()]\n",
    "        new_text = \" \".join([word for word in new_text if word not in use_stopwords])\n",
    "    else:\n",
    "        new_text = \"\"\n",
    "        for word in text:\n",
    "            if word not in use_stopwords:\n",
    "                new_text += word + \" \"\n",
    "\n",
    "    return new_text\n",
    "\n",
    "def sep_upper(text):\n",
    "    \"\"\" Take a text as input and insert space before every uppercase letter. \"\"\"\n",
    "    \n",
    "    new_text = \"\"\n",
    "    for letter in text:\n",
    "        if letter.isupper():\n",
    "            new_text += \" \" + letter\n",
    "        else:\n",
    "            new_text += letter\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "def remove_space(text):\n",
    "    return(re.sub(' +',' ',text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_proc(text_col):\n",
    "    text_col = text_col.apply(remove_punctuation) # removes String.punctuation characters\n",
    "    #text_col = text_col.apply(remove_stopwords)   # removes english stopwords \n",
    "    text_col = text_col.str.replace('[^\\w\\s]','').str.strip() # and removes whitespaces\n",
    "    text_col = text_col.apply(sep_upper) # adds space before an uppercase\n",
    "    text_col = text_col.str.lower() # lowercase\n",
    "    \n",
    "    return text_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.text = pre_proc(X_train.text)\n",
    "X_test.text = pre_proc(X_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['qtd_words'] = X_train.text.apply(count_words)\n",
    "X_test['qtd_words'] = X_test.text.apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>qtd_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>like if i had information i could dismiss fro...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>since my wife left   i ve bought a  harley  d...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>there s a man walking a tight rope  100ft bel...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>my wife yelled at me saying    you weren t ev...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>bipolar depression is technically referred to...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  qtd_words\n",
       "1705   like if i had information i could dismiss fro...         15\n",
       "6185   since my wife left   i ve bought a  harley  d...         36\n",
       "899    there s a man walking a tight rope  100ft bel...         33\n",
       "7453   my wife yelled at me saying    you weren t ev...         26\n",
       "2772   bipolar depression is technically referred to...         21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# additions by iago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. add weight balancing\n",
    " 2. define multiple classification models\n",
    " 3. plot the accuracy per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=class_labels,y= y_train)\n",
    "class_weights = dict(zip(class_labels, class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[1, 5, 7, 10]}\n",
    "\n",
    "svc = SVC(max_iter=10000,tol=0.00001,random_state=42,class_weight=class_weights,probability=True) #,class_weight=class_weights\n",
    "lr = LogisticRegression(max_iter=10000,tol=0.00001,class_weight=class_weights,random_state=42) #class_weight=class_weights,\n",
    "gridSearch = GridSearchCV(lr, param_grid=parameters, scoring='accuracy')\n",
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "models ={'svc':svc,\n",
    "         'lr':lr,\n",
    "         'grid_lr':gridSearch,\n",
    "         'mnb':mnb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc\n",
      "\t-> acc:  0.85\n",
      "\t-> recall:  0.8957915831663327\n",
      "\t-> prec:  0.8679611650485437\n",
      "lr\n",
      "\t-> acc:  0.8475\n",
      "\t-> recall:  0.8787575150300602\n",
      "\t-> prec:  0.877\n",
      "gnb\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-489ed1679e55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                       ])\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mprocess_and_join_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_and_join_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \"\"\"\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[0;32m    354\u001b[0m                         \u001b[1;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "get_numerical_data = FunctionTransformer(lambda x: x[['qtd_words']], validate=False)\n",
    "\n",
    "dictResults = {}\n",
    "for el in models.keys():\n",
    "    print(el)\n",
    "    process_and_join_features = Pipeline([('features', FeatureUnion([\n",
    "        ('text_features', Pipeline([('selector', get_text_data), \n",
    "                                ('vec', CountVectorizer())])),\n",
    "        ('nume_features', Pipeline([('selector', get_numerical_data), \n",
    "                                ('scaler', MinMaxScaler())]))\n",
    "        ])),\n",
    "        ('clf', models[el])\n",
    "                                      ])\n",
    "    process_and_join_features.fit(X_train, y_train)\n",
    "    y_pred = process_and_join_features.predict(X_test)\n",
    "    tn,fp,fn,tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "    acc = (tn + tp)/y_test.size\n",
    "    recall = tp/(tp + fn)\n",
    "    fpr = fp/(fp + tn)\n",
    "    prec = tp/(tp + fp)\n",
    "    print(\"\\t-> acc: \",acc)\n",
    "    print(\"\\t-> recall: \",recall)\n",
    "    print(\"\\t-> prec: \",prec)\n",
    "    dictResults[el] = [acc,recall,fpr,prec,tn,fp,fn,tp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model with best accuracy:  mnb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>fpr</th>\n",
       "      <th>prec</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.833125</td>\n",
       "      <td>0.827655</td>\n",
       "      <td>0.157807</td>\n",
       "      <td>0.896851</td>\n",
       "      <td>507.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>826.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.846250</td>\n",
       "      <td>0.851703</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.896624</td>\n",
       "      <td>504.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb</th>\n",
       "      <td>0.851250</td>\n",
       "      <td>0.913828</td>\n",
       "      <td>0.252492</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>450.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>912.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          acc    recall       fpr      prec     tn     fp     fn     tp\n",
       "svc  0.833125  0.827655  0.157807  0.896851  507.0   95.0  172.0  826.0\n",
       "lr   0.846250  0.851703  0.162791  0.896624  504.0   98.0  148.0  850.0\n",
       "mnb  0.851250  0.913828  0.252492  0.857143  450.0  152.0   86.0  912.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResults = pd.DataFrame(dictResults).transpose()\n",
    "dfResults.columns = ['acc','recall','fpr','prec','tn','fp','fn','tp']\n",
    "\n",
    "bestModel = dfResults['acc'].idxmax()\n",
    "print(\"model with best accuracy: \",bestModel)\n",
    "dfResults.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4. grid search for multinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(lr, param_grid=parameters, scoring='accuracy')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_join_features.fit(X_train, y_train)\n",
    "predicted_CountVectorizer = process_and_join_features.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85125\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_test, predicted_CountVectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Like if i had information i could dismiss from my brain it would be this'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1705].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' like if i had information i could dismiss from my brain it would be this'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[1705].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
