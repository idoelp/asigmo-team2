{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"iago_asigmo-team2_1a-classification_FastText_v0-1-0.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNtZbZ+c8jeRbZ8dTXBfdOU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LLQ76Myg3215"},"source":["#classification of humorous text using FastText \n","The Hahackaton aims at classifying text as humorous.\n","The dataset, a set of short texts, has been labeled by a group of heterogenous people (age, sex, race) under 4 features: \n","* is it humorous? (binary label) \n","* humour grading (0 to 5; 0 is not humorous)\n","* controversy (binary label): when the variance in the humour grading is higher than the average\n","* offensiveness grading (0 to 5; 0 is not offensive)\n","\n","In this approach, we use a FastText from the Gensim implementation \n","\n","| Attribute | *Accuracy* baseline | *f1-score* baseline |\n","| :-------- | ------------------: | ------------------: |\n","| is_humour | 86%                 | 88%                 |\n","| controversy | - | - |\n"]},{"cell_type":"markdown","metadata":{"id":"RkIHUGk1CwMD"},"source":["## import data"]},{"cell_type":"code","metadata":{"id":"LHrmpwzo3wAU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607165586848,"user_tz":-60,"elapsed":4072,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"5fb46cec-b1db-4ae2-e170-9e813f11d6a1"},"source":["import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline, FeatureUnion \n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n","from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import classification_report\n","\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"QoFuiGcHCzG6","executionInfo":{"status":"ok","timestamp":1607165624521,"user_tz":-60,"elapsed":786,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"f3119328-c72d-4132-ce32-affad269832a"},"source":["df = pd.read_csv('train.csv').drop(columns = 'id')\n","df.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>is_humor</th>\n","      <th>humor_rating</th>\n","      <th>humor_controversy</th>\n","      <th>offense_rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n","      <td>1</td>\n","      <td>2.42</td>\n","      <td>1.0</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A man inserted an advertisement in the classif...</td>\n","      <td>1</td>\n","      <td>2.50</td>\n","      <td>1.0</td>\n","      <td>1.1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>How many men does it take to open a can of bee...</td>\n","      <td>1</td>\n","      <td>1.95</td>\n","      <td>0.0</td>\n","      <td>2.4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n","      <td>1</td>\n","      <td>2.11</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n","      <td>1</td>\n","      <td>2.78</td>\n","      <td>0.0</td>\n","      <td>0.1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  ...  offense_rating\n","0  TENNESSEE: We're the best state. Nobody even c...  ...             0.2\n","1  A man inserted an advertisement in the classif...  ...             1.1\n","2  How many men does it take to open a can of bee...  ...             2.4\n","3  Told my mom I hit 1200 Twitter followers. She ...  ...             0.0\n","4  Roses are dead. Love is fake. Weddings are bas...  ...             0.1\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"b8XZHiC_aZzA"},"source":["## split data\n","* train (65%)\n","* valid (15%)\n","* test (20%)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"79Tq5hDkC3gZ","executionInfo":{"status":"ok","timestamp":1607165630051,"user_tz":-60,"elapsed":679,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"8f110e51-6d15-418e-bde1-78b011843a5d"},"source":["X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[['text']], \n","                                                    df['is_humor'], \n","                                                    test_size = 0.2, \n","                                                    random_state = 21)\n","X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_train_raw, \n","                                                    y_train, \n","                                                    test_size = 0.05, \n","                                                    random_state = 21)\n","X_train_raw.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2618</th>\n","      <td>me: so tell me about yourself date: i hate sur...</td>\n","    </tr>\n","    <tr>\n","      <th>898</th>\n","      <td>What do you call a zombified piece of toast? T...</td>\n","    </tr>\n","    <tr>\n","      <th>3722</th>\n","      <td>Today I came out to my parents, and my dad ins...</td>\n","    </tr>\n","    <tr>\n","      <th>3386</th>\n","      <td>A yellow pigment in curry and curcumin can sto...</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>What's green and not heavy? Light green h</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   text\n","2618  me: so tell me about yourself date: i hate sur...\n","898   What do you call a zombified piece of toast? T...\n","3722  Today I came out to my parents, and my dad ins...\n","3386  A yellow pigment in curry and curcumin can sto...\n","889           What's green and not heavy? Light green h"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"30kNYuwJU2yh","executionInfo":{"status":"ok","timestamp":1607165632100,"user_tz":-60,"elapsed":708,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"ed1f4a6a-b1e7-4875-9663-8d145b4db945"},"source":["X_train_raw.describe()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>6080</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>6080</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>My wife said I needed to grow up I was speechl...</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     text\n","count                                                6080\n","unique                                               6080\n","top     My wife said I needed to grow up I was speechl...\n","freq                                                    1"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itsdR7-JC9wa","executionInfo":{"status":"ok","timestamp":1607166257002,"user_tz":-60,"elapsed":674,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"22911d44-eaaa-416d-bd7c-5fc70f1c8e47"},"source":["total = len(y_train)\n","print('total labels',total)\n","print('of which NaNs in y : ', y_train.isna().sum())\n","print('of which NaNs in text: ', X_train.isna().sum())\n","print('\\n% of positives is ', round(y_train.sum()/total, 2)) #'% of positives is {:.2f}'.format(y_train.sum()/total)\n","print('% of negatives is ', round((total - y_train.sum())/total, 2)) #'% of negatives is {:.2f}'.format((total - y_train.sum())/total)\n","class_labels = np.unique(y_train)\n","class_weights = compute_class_weight(class_weight='balanced', classes=class_labels,y= y_train)\n","class_weights_dict = dict(zip(class_labels, class_weights))\n","print('class weights: ',class_weights_dict)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["total labels 6080\n","of which NaNs in y :  0\n","of which NaNs in text:  0\n","\n","% of positives is  0.61\n","% of negatives is  0.39\n","class weights:  {0: 1.2980358667805294, 1: 0.8132691278758695}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0cyvGJY0S-NH"},"source":["## data preprocessing\n","* remove punctuation (but dont remove stopwords)\n","* remove multiple sequential spaces\n","* everything to lower case\n","* stemming\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfppCr3jS9E-","executionInfo":{"status":"ok","timestamp":1607165794869,"user_tz":-60,"elapsed":3100,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"1b42ec1c-a1d8-4ef6-e497-32421ff9374c"},"source":["def stemmer(text, stemmer):\n","    return(' '.join([stemmer.stem(w) for w in word_tokenize(text)]))\n","\n","def lemmatize_text(text):\n","    lemmatizer = nltk.stem.WordNetLemmatizer()\n","    lemm_words = []\n","    for w in word_tokenize(text):\n","      w = lemmatizer.lemmatize(w,pos='n')\n","      w = lemmatizer.lemmatize(w,pos='v')\n","      lemm_words.append(w)\n","    lemmatized = \" \".join(lemm_words)\n","    return lemmatized\n","\n","def count_words(input):\n","    \"\"\" Returns number of occurences of characters specified in char \"\"\"     \n","    return len(input.split())\n","\n","def remove_punctuation(s_input, include_char = None):\n","    \"\"\" Returns input string without punctuation \"\"\"\n","    import string as String\n","    punct = String.punctuation\n","    \n","    if not include_char is None:\n","        index = String.punctuation.index(include_char)\n","        punct = String.punctuation[:index] + String.punctuation[(index + 1):]\n","        \n","    punct += '\\n'\n","        \n","    translator = str.maketrans(punct, ' '*len(punct))\n","    \n","    return s_input.translate(translator)\n","\n","def remove_stopwords(text, use_stopwords = None, df = True, exclude_number = True):\n","    \"\"\" Returns input string removing stopwords from it. \"\"\"\n","\n","    \n","    if use_stopwords is None:\n","        use_stopwords = set(stopwords.words(\"english\"))\n","        \n","    if df:\n","        new_text = word_tokenize(text)\n","        if exclude_number:\n","            new_text = [word for word in new_text if not word.isnumeric()]\n","        new_text = \" \".join([word for word in new_text if word not in use_stopwords])\n","    else:\n","        new_text = \"\"\n","        for word in text:\n","            if word not in use_stopwords:\n","                new_text += word + \" \"\n","\n","    return new_text\n","\n","def sep_upper(text):\n","    \"\"\" Take a text as input and insert space before every uppercase letter. \"\"\"\n","    \n","    new_text = \"\"\n","    for letter in text:\n","        if letter.isupper():\n","            new_text += \" \" + letter\n","        else:\n","            new_text += letter\n","    \n","    return new_text\n","\n","def remove_space(text):\n","    return(re.sub(' +',' ',text)) \n","\n","\n","def pre_proc(text_col):   \n","    text_col = text_col.str.lower() # lowercase\n","    text_col = text_col.apply(remove_punctuation) # removes String.punctuation characters\n","    #text_col = text_col.apply(remove_stopwords)   # removes english stopwords \n","    text_col = text_col.str.replace('[^\\w\\s]','').str.strip() # and removes whitespaces\n","    #text_col = text_col.apply(sep_upper) # adds space before an uppercase\n","    text_col = text_col.apply(lemmatize_text)   \n","    return text_col\n","\n","X_train = pre_proc(X_train_raw.text)\n","X_valid = pre_proc(X_valid_raw.text)\n","X_test = pre_proc(X_test_raw.text)\n","X_train.head()\n","#X_train_raw.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2618    me so tell me about yourself date i hate surpr...\n","898     what do you call a zombified piece of toast th...\n","3722    today i come out to my parent and my dad insta...\n","3386    a yellow pigment in curry and curcumin can sto...\n","889              what s green and not heavy light green h\n","Name: text, dtype: object"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"drZKiHqGk3kv","executionInfo":{"status":"ok","timestamp":1607175022810,"user_tz":-60,"elapsed":1876,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}}},"source":["def toFastTextFormat(series_x,series_y,filePath):\n","  \"\"\" \n","  transforms the data to a text file following \n","  the format required by L{fasttext.train_supervised}, that is, a text file\n","  where each line is a sentence preceded by the labels with format: \n","  C{__label__<label1> <sentence>}\n","  This function only allows one label\n","\n","\n","  @param series_x : a pandas series of str, named \"text\", with the sentences\n","  @type series_x: pandas.Series\n","  @param series_y : a pandas series with the labels for \"text\"\n","  @type series_y: pandas.Series\n","  @param filePath: the path for the text file to save\n","  @type filePath: str\n","\n","  @return: None \n","  \"\"\"\n","  xx = pd.DataFrame(series_x)\n","  xx['label'] = series_y\n","  xx['ft_label'] = '__label__'+xx['label'].astype(str)\n","  xx['ft_sent'] = xx['ft_label'] + ' ' + xx['text']\n","  ft_text = xx.ft_sent.str.cat(sep='\\n')\n","\n","  with open(filePath,\"w\") as fl:\n","    fl.write(ft_text)\n"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"jfghOnVB29d-","executionInfo":{"status":"ok","timestamp":1607175725922,"user_tz":-60,"elapsed":656,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}}},"source":["toFastTextFormat(X_train,y_train,'./train_text.txt')\n","toFastTextFormat(X_valid,y_valid,'./valid_text.txt')\n","toFastTextFormat(X_test,y_test,'./test_text.txt')"],"execution_count":82,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LRBA0pjmGV1u"},"source":["## FastText install and import"]},{"cell_type":"code","metadata":{"id":"koZBtPc-FIXs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607165695368,"user_tz":-60,"elapsed":19335,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"a68a32fa-71ac-4875-eec9-860a3c8f634d"},"source":["!git clone https://github.com/facebookresearch/fastText.git\n","%cd fastText\n","!make\n","!cp fasttext ../\n","%cd .."],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cloning into 'fastText'...\n","remote: Enumerating objects: 3854, done.\u001b[K\n","remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n","Receiving objects: 100% (3854/3854), 8.23 MiB | 33.96 MiB/s, done.\n","Resolving deltas: 100% (2416/2416), done.\n","/content/fastText\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPJILku4XU-O","executionInfo":{"status":"ok","timestamp":1607175167247,"user_tz":-60,"elapsed":46816,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"0767e25e-d7c2-4ab6-dcff-32cfe3737e0e"},"source":["!cd ./fastText && pip install ."],"execution_count":74,"outputs":[{"output_type":"stream","text":["Processing /content/fastText\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.6.1)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (50.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.18.5)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3037208 sha256=a9b00358723ed657994e0bb5281db2b5ff2bddf6fdbbf11ed725165c7154a0bd\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-rbb1a27b/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","  Found existing installation: fasttext 0.9.2\n","    Uninstalling fasttext-0.9.2:\n","      Successfully uninstalled fasttext-0.9.2\n","Successfully installed fasttext-0.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"559OE2V8TFP8","executionInfo":{"status":"ok","timestamp":1607175167248,"user_tz":-60,"elapsed":42222,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}}},"source":["import fasttext"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"0eSFZgNnZxgR","executionInfo":{"status":"ok","timestamp":1607176375452,"user_tz":-60,"elapsed":3505,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}}},"source":["model = fasttext.train_supervised(input=\"./train_text.txt\",lr=0.5, epoch=25,wordNgrams=2,ws=10,verbose=5)"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3xc4rFWHYNR","executionInfo":{"status":"ok","timestamp":1607175958067,"user_tz":-60,"elapsed":673,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}}},"source":["model.save_model('./model.bin')"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJvXbXnjHj8J","executionInfo":{"status":"ok","timestamp":1607178454677,"user_tz":-60,"elapsed":661,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"d6b9f942-6e2d-4ec7-c84f-31b581987513"},"source":["# quick test for humorous text: \"I invented a new word: plagiarism!\"\n","print(model.predict(\"i invented a new word plagiarism\")[0])\n","# quick test for non humorous text: \"facebook is an american online social media and social networking service based in menlo park california\"\n","print(model.predict(\"facebook is an american online social media and social networking service based in menlo park california\")[0])"],"execution_count":105,"outputs":[{"output_type":"stream","text":["('__label__1',)\n","('__label__0',)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYy1qOG5IL98","executionInfo":{"status":"ok","timestamp":1607178466769,"user_tz":-60,"elapsed":784,"user":{"displayName":"Iago Doel","photoUrl":"","userId":"03571942165532064316"}},"outputId":"c5f2fed8-84c2-4e4b-e91d-a852bee3b7dd"},"source":["model.test(\"./test_text.txt\")"],"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1600, 0.856875, 0.856875)"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"C9hljtSAIghP"},"source":[""],"execution_count":null,"outputs":[]}]}