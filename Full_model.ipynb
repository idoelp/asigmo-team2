{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Things first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#from sklearn.model_selection import RepeatedKFold\n",
    "import warnings # Ignore warning\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_humor  humor_rating  \\\n",
       "0  TENNESSEE: We're the best state. Nobody even c...         1          2.42   \n",
       "1  A man inserted an advertisement in the classif...         1          2.50   \n",
       "2  How many men does it take to open a can of bee...         1          1.95   \n",
       "3  Told my mom I hit 1200 Twitter followers. She ...         1          2.11   \n",
       "4  Roses are dead. Love is fake. Weddings are bas...         1          2.78   \n",
       "\n",
       "   humor_controversy  offense_rating  \n",
       "0                1.0             0.2  \n",
       "1                1.0             1.1  \n",
       "2                0.0             2.4  \n",
       "3                1.0             0.0  \n",
       "4                0.0             0.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../train.csv').drop(columns = 'id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text, stemmer):\n",
    "    return(' '.join([stemmer.stem(w) for w in word_tokenize(text)]))\n",
    "\n",
    "def count_words(input):\n",
    "    \"\"\" Returns number of occurences of characters specified in char \"\"\"     \n",
    "    return len(input.split())\n",
    "\n",
    "def remove_punctuation(s_input, include_char = None):\n",
    "    \"\"\" Returns input string without punctuation \"\"\"\n",
    "    import string as String\n",
    "    punct = String.punctuation\n",
    "    \n",
    "    if not include_char is None:\n",
    "        index = String.punctuation.index(include_char)\n",
    "        punct = String.punctuation[:index] + String.punctuation[(index + 1):]\n",
    "        \n",
    "    punct += '\\n'\n",
    "        \n",
    "    translator = str.maketrans(punct, ' '*len(punct))\n",
    "    \n",
    "    return s_input.translate(translator)\n",
    "\n",
    "def remove_stopwords(text, use_stopwords = None, df = True, exclude_number = True):\n",
    "    \"\"\" Returns input string removing stopwords from it. \"\"\"\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    if use_stopwords is None:\n",
    "        use_stopwords = set(stopwords.words(\"english\"))\n",
    "        \n",
    "    if df:\n",
    "        new_text = word_tokenize(text)\n",
    "        if exclude_number:\n",
    "            new_text = [word for word in new_text if not word.isnumeric()]\n",
    "        new_text = \" \".join([word for word in new_text if word not in use_stopwords])\n",
    "    else:\n",
    "        new_text = \"\"\n",
    "        for word in text:\n",
    "            if word not in use_stopwords:\n",
    "                new_text += word + \" \"\n",
    "\n",
    "    return new_text\n",
    "\n",
    "def sep_upper(text):\n",
    "    \"\"\" Take a text as input and insert space before every uppercase letter. \"\"\"\n",
    "    \n",
    "    new_text = \"\"\n",
    "    for letter in text:\n",
    "        if letter.isupper():\n",
    "            new_text += \" \" + letter\n",
    "        else:\n",
    "            new_text += letter\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "def remove_space(text):\n",
    "    return(re.sub(' +',' ',text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_proc(text_col):\n",
    "    text_col = text_col.apply(remove_punctuation) # removes String.punctuation characters\n",
    "    #text_col = text_col.apply(remove_stopwords)   # removes english stopwords \n",
    "    text_col = text_col.str.replace('[^\\w\\s]','').str.strip() # and removes whitespaces\n",
    "    text_col = text_col.apply(sep_upper) # adds space before an uppercase\n",
    "    text_col = text_col.str.lower() # lowercase\n",
    "    \n",
    "    return text_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a => is_humor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text']] #4932 Do not reset the index!\n",
    "y = df[['is_humor']] #4932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train and y_train shape: (6400, 1), (6400, 1), X_test and y_test shape (1600, 1), (1600, 1)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "\"X_train and y_train shape: {0}, {1}, X_test and y_test shape {2}, {3}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of positives is  is_humor    0.61\n",
      "dtype: float64\n",
      "% of negatives is  is_humor    0.39\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "total = len(y_train)\n",
    "print('% of positives is ', round(y_train.sum()/total, 2)) #'% of positives is {:.2f}'.format(y_train.sum()/total)\n",
    "print('% of negatives is ', round((total - y_train.sum())/total, 2)) #'% of negatives is {:.2f}'.format((total - y_train.sum())/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.text = pre_proc(X_train.text)\n",
    "X_test.text = pre_proc(X_test.text)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=4_000) # ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=4\n",
    "X_train_trans = pd.DataFrame(vectorizer.fit_transform(X_train.text).toarray()\n",
    "                             , columns = vectorizer.get_feature_names()\n",
    "                             , index = X_train.index)\n",
    "X_train_trans['qtd_words'] = X_train.text.apply(count_words)\n",
    "\n",
    "X_test_trans = pd.DataFrame(vectorizer.transform(X_test.text).toarray()\n",
    "                            , columns = vectorizer.get_feature_names()\n",
    "                            , index = X_test.index)\n",
    "X_test_trans['qtd_words'] = X_test.text.apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8822947576656776\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_trans, y_train.is_humor)\n",
    "\n",
    "y_pred = clf.predict(X_test_trans)\n",
    "print(f1_score(y_test.is_humor, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1a_vectorizer.pkl', 'wb') as file: \n",
    "    pickle.dump(vectorizer.vocabulary_, file) # countvectorizer\n",
    "with open('1a_clf.pkl', 'wb') as file: \n",
    "    pickle.dump(clf, file) # countvectorizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y, X_train, X_test, y_train, y_test, vectorizer, X_train_trans, X_test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b => humor_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df['is_humor']==1][['text']] # Do not reset the index!\n",
    "y = df[df['is_humor']==1][['humor_rating']] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train and y_train shape: (3945, 1), (3945, 1), X_test and y_test shape (987, 1), (987, 1)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "\"X_train and y_train shape: {0}, {1}, X_test and y_test shape {2}, {3}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.text = pre_proc(X_train.text)\n",
    "X_test.text = pre_proc(X_test.text)\n",
    "\n",
    "vectorizer = CountVectorizer() # ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=4\n",
    "\n",
    "X_train_trans = pd.DataFrame(vectorizer.fit_transform(X_train.text).toarray()\n",
    "                             , columns = vectorizer.get_feature_names()\n",
    "                             , index = X_train.index)\n",
    "X_train_trans['qtd_words'] = X_train.text.apply(count_words)\n",
    "\n",
    "X_test_trans = pd.DataFrame(vectorizer.transform(X_test.text).toarray()\n",
    "                            , columns = vectorizer.get_feature_names()\n",
    "                            , index = X_test.index)\n",
    "X_test_trans['qtd_words'] = X_test.text.apply(count_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipac\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 621.7380346263329, tolerance: 0.12784338972370093\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5508491704701347"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = ElasticNet(l1_ratio = 0.0)\n",
    "reg.fit(X_train_trans, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test_trans)\n",
    "mean_squared_error(y_test, y_pred, squared = False) # squared = F will return the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1b_vectorizer.pkl', 'wb') as file: \n",
    "    pickle.dump(vectorizer.vocabulary_, file) # countvectorizer\n",
    "with open('1b_reg.pkl', 'wb') as file: \n",
    "    pickle.dump(reg, file) # countvectorizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y, X_train, X_test, y_train, y_test, vectorizer, X_train_trans, X_test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c => humor_controversy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df['is_humor']==1][['text']] #4932 Do not reset the index!\n",
    "y = df[df['is_humor']==1][['humor_controversy']] #4932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train and y_train shape: (3945, 1), (3945, 1), X_test and y_test shape (987, 1), (987, 1)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "\"X_train and y_train shape: {0}, {1}, X_test and y_test shape {2}, {3}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of positives is  humor_controversy    0.5037\n",
      "dtype: float64\n",
      "% of negatives is  humor_controversy    0.4963\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "total = len(y_train)\n",
    "print('% of positives is ', round(y_train.sum()/total, 4)) #'% of positives is {:.2f}'.format(y_train.sum()/total)\n",
    "print('% of negatives is ', round((total - y_train.sum())/total, 4)) #'% of negatives is {:.2f}'.format((total - y_train.sum())/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549738219895288\n"
     ]
    }
   ],
   "source": [
    "X_train.text = pre_proc(X_train.text)\n",
    "X_test.text = pre_proc(X_test.text)\n",
    "\n",
    "#X_train['qtd_words'] = X_train.text.apply(count_words)\n",
    "#X_test['qtd_words'] = X_test.text.apply(count_words)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1000) # ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=4\n",
    "X_train_trans = pd.DataFrame(vectorizer.fit_transform(X_train.text).toarray()\n",
    "                             , columns = vectorizer.get_feature_names()\n",
    "                             , index = X_train.index)\n",
    "X_train_trans['qtd_words'] = X_train.text.apply(count_words)\n",
    "\n",
    "X_test_trans = pd.DataFrame(vectorizer.transform(X_test.text).toarray()\n",
    "                            , columns = vectorizer.get_feature_names()\n",
    "                            , index = X_test.index)\n",
    "X_test_trans['qtd_words'] = X_test.text.apply(count_words)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_trans, y_train.humor_controversy)\n",
    "\n",
    "y_pred = clf.predict(X_test_trans)\n",
    "print(f1_score(y_test.humor_controversy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1c_vectorizer.pkl', 'wb') as file: \n",
    "    pickle.dump(vectorizer.vocabulary_, file) # countvectorizer\n",
    "with open('1c_clf.pkl', 'wb') as file: \n",
    "    pickle.dump(clf, file) # countvectorizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y, X_train, X_test, y_train, y_test, vectorizer, X_train_trans, X_test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a => offense_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text']] #4932 Do not reset the index!\n",
    "y = df[['offense_rating']] #4932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train and y_train shape: (6400, 1), (6400, 1), X_test and y_test shape (1600, 1), (1600, 1)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "\"X_train and y_train shape: {0}, {1}, X_test and y_test shape {2}, {3}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:57:00] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.8121392197691781\n"
     ]
    }
   ],
   "source": [
    "X_train.text = pre_proc(X_train.text)\n",
    "X_test.text = pre_proc(X_test.text)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 5_00) # ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=4\n",
    "X_train_trans = pd.DataFrame(vectorizer.fit_transform(X_train.text).toarray()\n",
    "                             , columns = vectorizer.get_feature_names()\n",
    "                             , index = X_train.index)\n",
    "X_train_trans['qtd_words'] = X_train.text.apply(count_words)\n",
    "\n",
    "X_test_trans = pd.DataFrame(vectorizer.transform(X_test.text).toarray()\n",
    "                            , columns = vectorizer.get_feature_names()\n",
    "                            , index = X_test.index)\n",
    "X_test_trans['qtd_words'] = X_test.text.apply(count_words)\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "xgb_model.fit(X_train_trans, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_trans)\n",
    "mse=mean_squared_error( y_test, y_pred_xgb)\n",
    "\n",
    "print((mse)**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2a_vectorizer.pkl', 'wb') as file: \n",
    "    pickle.dump(vectorizer.vocabulary_, file) # countvectorizer\n",
    "with open('2a_reg.pkl', 'wb') as file: \n",
    "    pickle.dump(xgb_model, file) # countvectorizer    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
