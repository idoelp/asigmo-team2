{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First things first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import warnings # Ignore warning\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1c_clf.pkl\n",
      "1c_vectorizer.pkl\n",
      "Baseline.ipynb\n",
      "Public_Dev_Predictions.ipynb\n",
      "README.md\n",
      "humor_controversy_Baseline.ipynb\n",
      "humor_controversy_V1.ipynb\n",
      "humor_rating_Baseline.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_humor  humor_rating  \\\n",
       "0  TENNESSEE: We're the best state. Nobody even c...         1          2.42   \n",
       "1  A man inserted an advertisement in the classif...         1          2.50   \n",
       "2  How many men does it take to open a can of bee...         1          1.95   \n",
       "3  Told my mom I hit 1200 Twitter followers. She ...         1          2.11   \n",
       "4  Roses are dead. Love is fake. Weddings are bas...         1          2.78   \n",
       "\n",
       "   humor_controversy  offense_rating  \n",
       "0                1.0             0.2  \n",
       "1                1.0             1.1  \n",
       "2                0.0             2.4  \n",
       "3                1.0             0.0  \n",
       "4                0.0             0.1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../train.csv').drop(columns = 'id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                    0\n",
       "is_humor                0\n",
       "humor_rating         3068\n",
       "humor_controversy    3068\n",
       "offense_rating          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.is_humor ==0].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### selecting rows where the text is classified as humorous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df['is_humor']==1][['text']] #4932 Do not reset the index!\n",
    "y = df[df['is_humor']==1][['humor_controversy']] #4932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train and y_train shape: (3945, 1), (3945, 1), X_test and y_test shape (987, 1), (987, 1)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "\"X_train and y_train shape: {0}, {1}, X_test and y_test shape {2}, {3}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of positives is  humor_controversy    0.5037\n",
      "dtype: float64\n",
      "% of negatives is  humor_controversy    0.4963\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "total = len(y_train)\n",
    "print('% of positives is ', round(y_train.sum()/total, 4)) #'% of positives is {:.2f}'.format(y_train.sum()/total)\n",
    "print('% of negatives is ', round((total - y_train.sum())/total, 4)) #'% of negatives is {:.2f}'.format((total - y_train.sum())/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text, stemmer):\n",
    "    return(' '.join([stemmer.stem(w) for w in word_tokenize(text)]))\n",
    "\n",
    "def count_words(input):\n",
    "    \"\"\" Returns number of occurences of characters specified in char \"\"\"     \n",
    "    return len(input.split())\n",
    "\n",
    "def remove_punctuation(s_input, include_char = None):\n",
    "    \"\"\" Returns input string without punctuation \"\"\"\n",
    "    import string as String\n",
    "    punct = String.punctuation\n",
    "    \n",
    "    if not include_char is None:\n",
    "        index = String.punctuation.index(include_char)\n",
    "        punct = String.punctuation[:index] + String.punctuation[(index + 1):]\n",
    "        \n",
    "    punct += '\\n'\n",
    "        \n",
    "    translator = str.maketrans(punct, ' '*len(punct))\n",
    "    \n",
    "    return s_input.translate(translator)\n",
    "\n",
    "def remove_stopwords(text, use_stopwords = None, df = True, exclude_number = True):\n",
    "    \"\"\" Returns input string removing stopwords from it. \"\"\"\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    if use_stopwords is None:\n",
    "        use_stopwords = set(stopwords.words(\"english\"))\n",
    "        \n",
    "    if df:\n",
    "        new_text = word_tokenize(text)\n",
    "        if exclude_number:\n",
    "            new_text = [word for word in new_text if not word.isnumeric()]\n",
    "        new_text = \" \".join([word for word in new_text if word not in use_stopwords])\n",
    "    else:\n",
    "        new_text = \"\"\n",
    "        for word in text:\n",
    "            if word not in use_stopwords:\n",
    "                new_text += word + \" \"\n",
    "\n",
    "    return new_text\n",
    "\n",
    "def sep_upper(text):\n",
    "    \"\"\" Take a text as input and insert space before every uppercase letter. \"\"\"\n",
    "    \n",
    "    new_text = \"\"\n",
    "    for letter in text:\n",
    "        if letter.isupper():\n",
    "            new_text += \" \" + letter\n",
    "        else:\n",
    "            new_text += letter\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "def remove_space(text):\n",
    "    return(re.sub(' +',' ',text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (basic) pre-process of text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_proc(text_col):\n",
    "    text_col = text_col.apply(remove_punctuation) # removes String.punctuation characters\n",
    "    #text_col = text_col.apply(remove_stopwords)   # removes english stopwords \n",
    "    text_col = text_col.str.replace('[^\\w\\s]','').str.strip() # and removes whitespaces\n",
    "    text_col = text_col.apply(sep_upper) # adds space before an uppercase\n",
    "    text_col = text_col.str.lower() # lowercase\n",
    "    \n",
    "    return text_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n",
      "new fold!\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state = 21)\n",
    "#rkf.get_n_splits(X_train) # 5folds x 5times\n",
    "\n",
    "f1scores = []\n",
    "for train_index, test_index in rkf.split(X_train):\n",
    "    #print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "    print('new fold!')\n",
    "    X_kf_train, X_kf_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_kf_train, y_kf_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    X_kf_train.text = pre_proc(X_kf_train.text)\n",
    "    X_kf_test.text = pre_proc(X_kf_test.text)\n",
    "    \n",
    "    X_kf_train['qtd_words'] = X_kf_train.text.apply(count_words)\n",
    "    X_kf_test['qtd_words'] = X_kf_test.text.apply(count_words)\n",
    "    \n",
    "    vectorizer = CountVectorizer() # ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=4\n",
    "    X_train_trans = pd.DataFrame(vectorizer.fit_transform(X_kf_train.text).toarray()\n",
    "                                 , columns = vectorizer.get_feature_names()\n",
    "                                 , index = X_kf_train.index)\n",
    "    X_train_trans['qtd_words'] = X_kf_train['qtd_words']\n",
    "\n",
    "    X_test_trans = pd.DataFrame(vectorizer.transform(X_kf_test.text).toarray()\n",
    "                                , columns = vectorizer.get_feature_names()\n",
    "                                , index = X_kf_test.index)\n",
    "    X_test_trans['qtd_words'] = X_kf_test['qtd_words']\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_trans, y_kf_train.humor_controversy)\n",
    "\n",
    "    y_kf_pred = clf.predict(X_test_trans)\n",
    "    f1scores.append(f1_score(y_kf_test.humor_controversy, y_kf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5174270843173556"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f1scores)/len(f1scores) # F1 score from CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49115504682622274\n"
     ]
    }
   ],
   "source": [
    "X_train.text = pre_proc(X_train.text)\n",
    "X_test.text = pre_proc(X_test.text)\n",
    "\n",
    "#X_train['qtd_words'] = X_train.text.apply(count_words)\n",
    "#X_test['qtd_words'] = X_test.text.apply(count_words)\n",
    "\n",
    "vectorizer = CountVectorizer() # ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=4\n",
    "X_train_trans = pd.DataFrame(vectorizer.fit_transform(X_train.text).toarray()\n",
    "                             , columns = vectorizer.get_feature_names()\n",
    "                             , index = X_train.index)\n",
    "X_train_trans['qtd_words'] = X_train.text.apply(count_words)\n",
    "\n",
    "X_test_trans = pd.DataFrame(vectorizer.transform(X_test.text).toarray()\n",
    "                            , columns = vectorizer.get_feature_names()\n",
    "                            , index = X_test.index)\n",
    "X_test_trans['qtd_words'] = X_test.text.apply(count_words)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_trans, y_train.humor_controversy)\n",
    "\n",
    "y_pred = clf.predict(X_test_trans)\n",
    "print(f1_score(y_test.humor_controversy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1c_vectorizer.pkl', 'wb') as file: \n",
    "    pickle.dump(vectorizer.vocabulary_, file) # countvectorizer\n",
    "with open('1c_clf.pkl', 'wb') as file: \n",
    "    pickle.dump(clf, file) # countvectorizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1705].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[1705].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
