{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('~/Asigmo/AI Ethics/train_humour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       TENNESSEE: We're the best state. Nobody even c...\n",
       "1       A man inserted an advertisement in the classif...\n",
       "2       How many men does it take to open a can of bee...\n",
       "3       Told my mom I hit 1200 Twitter followers. She ...\n",
       "4       Roses are dead. Love is fake. Weddings are bas...\n",
       "                              ...                        \n",
       "7995    Lack of awareness of the pervasiveness of raci...\n",
       "7996      Why are aspirins white? Because they work sorry\n",
       "7997    Today, we Americans celebrate our independence...\n",
       "7998    How to keep the flies off the bride at an Ital...\n",
       "7999    \"Each ounce of sunflower seeds gives you 37% o...\n",
       "Name: text, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>7969</td>\n",
       "      <td>I saw a guy walking 4 dogs this morning and th...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>7703</td>\n",
       "      <td>BOOK: She gazed upon the sun-dappled lawn. ME:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>6101</td>\n",
       "      <td>Pandas show little interest in company or frie...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>3987</td>\n",
       "      <td>The word 'infant' originates from the Latin wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>7389</td>\n",
       "      <td>\"The spaces between us, keep getting deeper.' ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>7190</td>\n",
       "      <td>Don't chase anyone. Don't beg anyone to stay. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>7839</td>\n",
       "      <td>Verily, the land does not make anyone holy; it...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>3647</td>\n",
       "      <td>Let's talk about sax, baby Let's talk about br...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>7772</td>\n",
       "      <td>My girlfriends threatened to leave me because ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>4974</td>\n",
       "      <td>I thought I won the argument with my wife as t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>1721</td>\n",
       "      <td>The most unrealistic part of action movies is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>621</td>\n",
       "      <td>la croix tastes like orange crush that gave up...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1657</td>\n",
       "      <td>60% of African American girls agree to giving ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>We think that mental health is important to mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>7401</td>\n",
       "      <td>\"Dad, on my way home from school I saw Santa b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>1421</td>\n",
       "      <td>Hopefully no one ever sees those shorts I was ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3070</td>\n",
       "      <td>Hummus as a whole contains plenty of Omega 3 f...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>4482</td>\n",
       "      <td>How do you excite an idiot? I'll tell you later.</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>6698</td>\n",
       "      <td>Mohammed spent a lot of time up mountains, sla...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7121</th>\n",
       "      <td>7122</td>\n",
       "      <td>So my girlfriend just told me that she needed ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "7968  7969  I saw a guy walking 4 dogs this morning and th...         1   \n",
       "7702  7703  BOOK: She gazed upon the sun-dappled lawn. ME:...         1   \n",
       "6100  6101  Pandas show little interest in company or frie...         0   \n",
       "3986  3987  The word 'infant' originates from the Latin wo...         0   \n",
       "7388  7389  \"The spaces between us, keep getting deeper.' ...         0   \n",
       "7189  7190  Don't chase anyone. Don't beg anyone to stay. ...         0   \n",
       "7838  7839  Verily, the land does not make anyone holy; it...         0   \n",
       "3646  3647  Let's talk about sax, baby Let's talk about br...         1   \n",
       "7771  7772  My girlfriends threatened to leave me because ...         1   \n",
       "4973  4974  I thought I won the argument with my wife as t...         1   \n",
       "1720  1721  The most unrealistic part of action movies is ...         1   \n",
       "620    621  la croix tastes like orange crush that gave up...         1   \n",
       "1656  1657  60% of African American girls agree to giving ...         1   \n",
       "1588  1589  We think that mental health is important to mi...         0   \n",
       "7400  7401  \"Dad, on my way home from school I saw Santa b...         1   \n",
       "1420  1421  Hopefully no one ever sees those shorts I was ...         1   \n",
       "3069  3070  Hummus as a whole contains plenty of Omega 3 f...         0   \n",
       "4481  4482   How do you excite an idiot? I'll tell you later.         1   \n",
       "6697  6698  Mohammed spent a lot of time up mountains, sla...         1   \n",
       "7121  7122  So my girlfriend just told me that she needed ...         1   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  \n",
       "7968          2.00                1.0            0.55  \n",
       "7702          1.76                1.0            0.00  \n",
       "6100           NaN                NaN            0.00  \n",
       "3986           NaN                NaN            0.10  \n",
       "7388           NaN                NaN            0.00  \n",
       "7189           NaN                NaN            0.00  \n",
       "7838           NaN                NaN            0.00  \n",
       "3646          2.38                0.0            0.00  \n",
       "7771          2.32                0.0            0.00  \n",
       "4973          2.60                1.0            0.00  \n",
       "1720          2.68                1.0            0.00  \n",
       "620           2.41                1.0            0.15  \n",
       "1656          1.11                0.0            4.05  \n",
       "1588           NaN                NaN            0.05  \n",
       "7400          0.89                0.0            3.25  \n",
       "1420          0.71                0.0            0.00  \n",
       "3069           NaN                NaN            0.00  \n",
       "4481          1.70                1.0            0.20  \n",
       "6697          2.37                1.0            2.95  \n",
       "7121          2.50                1.0            0.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/histograms.py:839: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/histograms.py:840: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  14.,   49.,  157.,  488., 1048., 1219., 1157.,  630.,  152.,\n",
       "          18.]),\n",
       " array([0.1 , 0.49, 0.88, 1.27, 1.66, 2.05, 2.44, 2.83, 3.22, 3.61, 4.  ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.humor_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3068.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        4932.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.is_humor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data[data.is_humor==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 8000 non-null   int64  \n",
      " 1   text               8000 non-null   object \n",
      " 2   is_humor           8000 non-null   int64  \n",
      " 3   humor_rating       4932 non-null   float64\n",
      " 4   humor_controversy  4932 non-null   float64\n",
      " 5   offense_rating     8000 non-null   float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 375.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.humor_rating.fillna(value = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>4932.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4000.50000</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>1.393614</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.585325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2309.54541</td>\n",
       "      <td>0.486269</td>\n",
       "      <td>1.185941</td>\n",
       "      <td>0.500051</td>\n",
       "      <td>0.979955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2000.75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4000.50000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6000.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     is_humor  humor_rating  humor_controversy  \\\n",
       "count  8000.00000  8000.000000   8000.000000        4932.000000   \n",
       "mean   4000.50000     0.616500      1.393614           0.499797   \n",
       "std    2309.54541     0.486269      1.185941           0.500051   \n",
       "min       1.00000     0.000000      0.000000           0.000000   \n",
       "25%    2000.75000     0.000000      0.000000           0.000000   \n",
       "50%    4000.50000     1.000000      1.760000           0.000000   \n",
       "75%    6000.25000     1.000000      2.420000           1.000000   \n",
       "max    8000.00000     1.000000      4.000000           1.000000   \n",
       "\n",
       "       offense_rating  \n",
       "count     8000.000000  \n",
       "mean         0.585325  \n",
       "std          0.979955  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.100000  \n",
       "75%          0.700000  \n",
       "max          4.850000  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_humor  humor_rating  \\\n",
       "0  TENNESSEE: We're the best state. Nobody even c...         1          2.42   \n",
       "1  A man inserted an advertisement in the classif...         1          2.50   \n",
       "2  How many men does it take to open a can of bee...         1          1.95   \n",
       "3  Told my mom I hit 1200 Twitter followers. She ...         1          2.11   \n",
       "4  Roses are dead. Love is fake. Weddings are bas...         1          2.78   \n",
       "\n",
       "   offense_rating  \n",
       "0             0.2  \n",
       "1             1.1  \n",
       "2             2.4  \n",
       "3             0.0  \n",
       "4             0.1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.drop(columns=['humor_controversy','id'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "tokenizer.tokenize(text)\n",
    "\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "tokenizer.tokenize(text)\n",
    "\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_humor = df['is_humor']\n",
    "X_humor = df.drop(columns='is_humor')\n",
    "X_humor.text = X_humor.text.str.lower()\n",
    "X_humor_train, X_humor_test, y_humor_train, y_humor_test = train_test_split\\\n",
    "                                            (X_humor, y_humor, test_size = 0.2, random_state=101, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>just because people do horrible things... it d...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5808</th>\n",
       "      <td>did you hear about the asian kid who had that ...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>the wife has piled on the pounds of late, last...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7525</th>\n",
       "      <td>my new girlfriend works at the zoo. i think sh...</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>what do you call a mushroom who strongly belie...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  humor_rating  \\\n",
       "5360  just because people do horrible things... it d...          0.00   \n",
       "5808  did you hear about the asian kid who had that ...          2.00   \n",
       "5297  the wife has piled on the pounds of late, last...          2.20   \n",
       "7525  my new girlfriend works at the zoo. i think sh...          3.16   \n",
       "780   what do you call a mushroom who strongly belie...          2.20   \n",
       "\n",
       "      offense_rating  \n",
       "5360            0.00  \n",
       "5808            1.90  \n",
       "5297            1.65  \n",
       "7525            0.00  \n",
       "780             1.40  "
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_humor_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/festo.owiny/Asigmo/hahackathon/pos_neg_list/stopwords.txt') as f:\n",
    "    stop_words = [line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopworder(df):\n",
    "    stop_list = df['text'].apply(lambda x: [item for item in x.split() if item not in stop_words])\n",
    "    stop_sentence = stop_list.apply(lambda x : \" \".join(x))\n",
    "    return (stop_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stop_sentence</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just because people do horrible things... it d...</td>\n",
       "      <td>just people do horrible things... doesn't alwa...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>did you hear about the asian kid who had that ...</td>\n",
       "      <td>did hear asian kid one night stand? too many b...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wife has piled on the pounds of late, last...</td>\n",
       "      <td>wife piled pounds late, last night came home w...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my new girlfriend works at the zoo. i think sh...</td>\n",
       "      <td>new girlfriend works zoo. think keeper.</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what do you call a mushroom who strongly belie...</td>\n",
       "      <td>do call mushroom strongly believes radical isl...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  just because people do horrible things... it d...   \n",
       "1  did you hear about the asian kid who had that ...   \n",
       "2  the wife has piled on the pounds of late, last...   \n",
       "3  my new girlfriend works at the zoo. i think sh...   \n",
       "4  what do you call a mushroom who strongly belie...   \n",
       "\n",
       "                                       stop_sentence  humor_rating  \\\n",
       "0  just people do horrible things... doesn't alwa...          0.00   \n",
       "1  did hear asian kid one night stand? too many b...          2.00   \n",
       "2  wife piled pounds late, last night came home w...          2.20   \n",
       "3            new girlfriend works zoo. think keeper.          3.16   \n",
       "4  do call mushroom strongly believes radical isl...          2.20   \n",
       "\n",
       "   offense_rating  \n",
       "0            0.00  \n",
       "1            1.90  \n",
       "2            1.65  \n",
       "3            0.00  \n",
       "4            1.40  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_train = stopworder(X_humor_train).tolist()\n",
    "\n",
    "X_humor_train.reset_index(drop=True, inplace=True)\n",
    "X_humor_train.insert(1, \"stop_sentence\", stop_train, True)\n",
    "X_humor_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stop_sentence</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what do you call a muslim woman without a burk...</td>\n",
       "      <td>do call muslim woman without burka? dead.</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last night in bed, my wife said we should try ...</td>\n",
       "      <td>last night bed, wife said try role reversal. t...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>educator and feminist jackie anderson was a po...</td>\n",
       "      <td>educator feminist jackie anderson powerhouse l...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>house reno question! does anyone know of a goo...</td>\n",
       "      <td>house reno question! does anyone know good mos...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the issue is complex, but one thing is clear. ...</td>\n",
       "      <td>issue complex, one thing clear. 's better unde...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  what do you call a muslim woman without a burk...   \n",
       "1  last night in bed, my wife said we should try ...   \n",
       "2  educator and feminist jackie anderson was a po...   \n",
       "3  house reno question! does anyone know of a goo...   \n",
       "4  the issue is complex, but one thing is clear. ...   \n",
       "\n",
       "                                       stop_sentence  humor_rating  \\\n",
       "0          do call muslim woman without burka? dead.          2.17   \n",
       "1  last night bed, wife said try role reversal. t...          2.55   \n",
       "2  educator feminist jackie anderson powerhouse l...          0.00   \n",
       "3  house reno question! does anyone know good mos...          0.00   \n",
       "4  issue complex, one thing clear. 's better unde...          0.00   \n",
       "\n",
       "   offense_rating  \n",
       "0             3.5  \n",
       "1             0.4  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  "
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_test = stopworder(X_humor_test).tolist()\n",
    "\n",
    "X_humor_test.reset_index(drop=True, inplace=True)\n",
    "X_humor_test.insert(1, \"stop_sentence\", stop_test, True)\n",
    "X_humor_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer\n",
      "cat\n",
      "troubl\n",
      "troubl\n",
      "troubl\n",
      "Lancaster Stemmer\n",
      "cat\n",
      "troubl\n",
      "troubl\n",
      "troubl\n"
     ]
    }
   ],
   "source": [
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()\n",
    "#proide a word to be stemmed\n",
    "print(\"Porter Stemmer\")\n",
    "print(porter.stem(\"cats\"))\n",
    "print(porter.stem(\"trouble\"))\n",
    "print(porter.stem(\"troubling\"))\n",
    "print(porter.stem(\"troubled\"))\n",
    "print(\"Lancaster Stemmer\")\n",
    "print(lancaster.stem(\"cats\"))\n",
    "print(lancaster.stem(\"trouble\"))\n",
    "print(lancaster.stem(\"troubling\"))\n",
    "print(lancaster.stem(\"troubled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmmer(df):\n",
    "    stemmed = (df['text'].str.split()).apply(lambda x : [porter.stem(y) for y in x])\n",
    "    stemmed_sentence = stemmed.apply(lambda x : \" \".join(x))\n",
    "    return (stemmed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_sentence</th>\n",
       "      <th>stop_sentence</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just because people do horrible things... it d...</td>\n",
       "      <td>just becaus peopl do horribl things... it does...</td>\n",
       "      <td>just people do horrible things... doesn't alwa...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>did you hear about the asian kid who had that ...</td>\n",
       "      <td>did you hear about the asian kid who had that ...</td>\n",
       "      <td>did hear asian kid one night stand? too many b...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wife has piled on the pounds of late, last...</td>\n",
       "      <td>the wife ha pile on the pound of late, last ni...</td>\n",
       "      <td>wife piled pounds late, last night came home w...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my new girlfriend works at the zoo. i think sh...</td>\n",
       "      <td>my new girlfriend work at the zoo. i think she...</td>\n",
       "      <td>new girlfriend works zoo. think keeper.</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what do you call a mushroom who strongly belie...</td>\n",
       "      <td>what do you call a mushroom who strongli belie...</td>\n",
       "      <td>do call mushroom strongly believes radical isl...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  just because people do horrible things... it d...   \n",
       "1  did you hear about the asian kid who had that ...   \n",
       "2  the wife has piled on the pounds of late, last...   \n",
       "3  my new girlfriend works at the zoo. i think sh...   \n",
       "4  what do you call a mushroom who strongly belie...   \n",
       "\n",
       "                                    stemmed_sentence  \\\n",
       "0  just becaus peopl do horribl things... it does...   \n",
       "1  did you hear about the asian kid who had that ...   \n",
       "2  the wife ha pile on the pound of late, last ni...   \n",
       "3  my new girlfriend work at the zoo. i think she...   \n",
       "4  what do you call a mushroom who strongli belie...   \n",
       "\n",
       "                                       stop_sentence  humor_rating  \\\n",
       "0  just people do horrible things... doesn't alwa...          0.00   \n",
       "1  did hear asian kid one night stand? too many b...          2.00   \n",
       "2  wife piled pounds late, last night came home w...          2.20   \n",
       "3            new girlfriend works zoo. think keeper.          3.16   \n",
       "4  do call mushroom strongly believes radical isl...          2.20   \n",
       "\n",
       "   offense_rating  \n",
       "0            0.00  \n",
       "1            1.90  \n",
       "2            1.65  \n",
       "3            0.00  \n",
       "4            1.40  "
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_train = stemmmer(X_humor_train).tolist()\n",
    "\n",
    "X_humor_train.reset_index(drop=True, inplace=True)\n",
    "X_humor_train.insert(1, \"stemmed_sentence\", stemmed_train, True)\n",
    "X_humor_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_sentence</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what do you call a muslim woman without a burk...</td>\n",
       "      <td>what do you call a muslim woman without a burk...</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last night in bed, my wife said we should try ...</td>\n",
       "      <td>last night in bed, my wife said we should tri ...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>educator and feminist jackie anderson was a po...</td>\n",
       "      <td>educ and feminist jacki anderson wa a powerhou...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>house reno question! does anyone know of a goo...</td>\n",
       "      <td>hous reno question! doe anyon know of a good m...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the issue is complex, but one thing is clear. ...</td>\n",
       "      <td>the issu is complex, but one thing is clear. i...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  what do you call a muslim woman without a burk...   \n",
       "1  last night in bed, my wife said we should try ...   \n",
       "2  educator and feminist jackie anderson was a po...   \n",
       "3  house reno question! does anyone know of a goo...   \n",
       "4  the issue is complex, but one thing is clear. ...   \n",
       "\n",
       "                                    stemmed_sentence  humor_rating  \\\n",
       "0  what do you call a muslim woman without a burk...          2.17   \n",
       "1  last night in bed, my wife said we should tri ...          2.55   \n",
       "2  educ and feminist jacki anderson wa a powerhou...          0.00   \n",
       "3  hous reno question! doe anyon know of a good m...          0.00   \n",
       "4  the issu is complex, but one thing is clear. i...          0.00   \n",
       "\n",
       "   offense_rating  \n",
       "0             3.5  \n",
       "1             0.4  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  "
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_test = stemmmer(X_humor_test).tolist()\n",
    "\n",
    "X_humor_test.reset_index(drop=True, inplace=True)\n",
    "X_humor_test.insert(1, \"stemmed_sentence\", stemmed_test, True)\n",
    "X_humor_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return (\" \".join([lemmatizer.lemmatize(w, pos=\"v\") for w in w_tokenizer.tokenize(text)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized_sentence</th>\n",
       "      <th>stemmed_sentence</th>\n",
       "      <th>stop_sentence</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just because people do horrible things... it d...</td>\n",
       "      <td>just because people do horrible things... it d...</td>\n",
       "      <td>just becaus peopl do horribl things... it does...</td>\n",
       "      <td>just people do horrible things... doesn't alwa...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>did you hear about the asian kid who had that ...</td>\n",
       "      <td>do you hear about the asian kid who have that ...</td>\n",
       "      <td>did you hear about the asian kid who had that ...</td>\n",
       "      <td>did hear asian kid one night stand? too many b...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wife has piled on the pounds of late, last...</td>\n",
       "      <td>the wife have pile on the pound of late, last ...</td>\n",
       "      <td>the wife ha pile on the pound of late, last ni...</td>\n",
       "      <td>wife piled pounds late, last night came home w...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my new girlfriend works at the zoo. i think sh...</td>\n",
       "      <td>my new girlfriend work at the zoo. i think she...</td>\n",
       "      <td>my new girlfriend work at the zoo. i think she...</td>\n",
       "      <td>new girlfriend works zoo. think keeper.</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what do you call a mushroom who strongly belie...</td>\n",
       "      <td>what do you call a mushroom who strongly belie...</td>\n",
       "      <td>what do you call a mushroom who strongli belie...</td>\n",
       "      <td>do call mushroom strongly believes radical isl...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  just because people do horrible things... it d...   \n",
       "1  did you hear about the asian kid who had that ...   \n",
       "2  the wife has piled on the pounds of late, last...   \n",
       "3  my new girlfriend works at the zoo. i think sh...   \n",
       "4  what do you call a mushroom who strongly belie...   \n",
       "\n",
       "                                 lemmatized_sentence  \\\n",
       "0  just because people do horrible things... it d...   \n",
       "1  do you hear about the asian kid who have that ...   \n",
       "2  the wife have pile on the pound of late, last ...   \n",
       "3  my new girlfriend work at the zoo. i think she...   \n",
       "4  what do you call a mushroom who strongly belie...   \n",
       "\n",
       "                                    stemmed_sentence  \\\n",
       "0  just becaus peopl do horribl things... it does...   \n",
       "1  did you hear about the asian kid who had that ...   \n",
       "2  the wife ha pile on the pound of late, last ni...   \n",
       "3  my new girlfriend work at the zoo. i think she...   \n",
       "4  what do you call a mushroom who strongli belie...   \n",
       "\n",
       "                                       stop_sentence  humor_rating  \\\n",
       "0  just people do horrible things... doesn't alwa...          0.00   \n",
       "1  did hear asian kid one night stand? too many b...          2.00   \n",
       "2  wife piled pounds late, last night came home w...          2.20   \n",
       "3            new girlfriend works zoo. think keeper.          3.16   \n",
       "4  do call mushroom strongly believes radical isl...          2.20   \n",
       "\n",
       "   offense_rating  \n",
       "0            0.00  \n",
       "1            1.90  \n",
       "2            1.65  \n",
       "3            0.00  \n",
       "4            1.40  "
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_train = X_humor_train.text.apply(lemmatize_text).tolist()\n",
    "\n",
    "X_humor_train.reset_index(drop=True, inplace=True)\n",
    "X_humor_train.insert(1, \"lemmatized_sentence\", lemmatized_train, True)\n",
    "X_humor_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized_sentence</th>\n",
       "      <th>stemmed_sentence</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what do you call a muslim woman without a burk...</td>\n",
       "      <td>what do you call a muslim woman without a burk...</td>\n",
       "      <td>what do you call a muslim woman without a burk...</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last night in bed, my wife said we should try ...</td>\n",
       "      <td>last night in bed, my wife say we should try s...</td>\n",
       "      <td>last night in bed, my wife said we should tri ...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>educator and feminist jackie anderson was a po...</td>\n",
       "      <td>educator and feminist jackie anderson be a pow...</td>\n",
       "      <td>educ and feminist jacki anderson wa a powerhou...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>house reno question! does anyone know of a goo...</td>\n",
       "      <td>house reno question! do anyone know of a good ...</td>\n",
       "      <td>hous reno question! doe anyon know of a good m...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the issue is complex, but one thing is clear. ...</td>\n",
       "      <td>the issue be complex, but one thing be clear. ...</td>\n",
       "      <td>the issu is complex, but one thing is clear. i...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  what do you call a muslim woman without a burk...   \n",
       "1  last night in bed, my wife said we should try ...   \n",
       "2  educator and feminist jackie anderson was a po...   \n",
       "3  house reno question! does anyone know of a goo...   \n",
       "4  the issue is complex, but one thing is clear. ...   \n",
       "\n",
       "                                 lemmatized_sentence  \\\n",
       "0  what do you call a muslim woman without a burk...   \n",
       "1  last night in bed, my wife say we should try s...   \n",
       "2  educator and feminist jackie anderson be a pow...   \n",
       "3  house reno question! do anyone know of a good ...   \n",
       "4  the issue be complex, but one thing be clear. ...   \n",
       "\n",
       "                                    stemmed_sentence  humor_rating  \\\n",
       "0  what do you call a muslim woman without a burk...          2.17   \n",
       "1  last night in bed, my wife said we should tri ...          2.55   \n",
       "2  educ and feminist jacki anderson wa a powerhou...          0.00   \n",
       "3  hous reno question! doe anyon know of a good m...          0.00   \n",
       "4  the issu is complex, but one thing is clear. i...          0.00   \n",
       "\n",
       "   offense_rating  \n",
       "0             3.5  \n",
       "1             0.4  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_test = X_humor_test.text.apply(lemmatize_text).tolist()\n",
    "\n",
    "X_humor_test.reset_index(drop=True, inplace=True)\n",
    "X_humor_test.insert(1, \"lemmatized_sentence\", lemmatized_test, True)\n",
    "X_humor_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuations and digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "#puncs1 = string.punctuation\n",
    "puncs = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "exclude = set(puncs + string.digits)\n",
    "\n",
    "def remove_punctuation(x):\n",
    "    \"\"\"\n",
    "    Helper function to remove punctuation from a string\n",
    "    x: any string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = ''.join(ch for ch in x if ch not in exclude)\n",
    "    except:\n",
    "        pass\n",
    "    res = re.sub(' +', ' ', x)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what do you call a muslim woman without a burk...\n",
       "1    last night in bed my wife say we should try so...\n",
       "2    educator and feminist jackie anderson be a pow...\n",
       "3    house reno question do anyone know of a good m...\n",
       "4    the issue be complex but one thing be clear it...\n",
       "Name: lemmatized_sentence, dtype: object"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text = X_humor_train.lemmatized_sentence.apply(remove_punctuation).str.strip().str.strip()\n",
    "X_train_text.reset_index(drop=True, inplace=True)\n",
    "X_train_text.head()\n",
    "\n",
    "\n",
    "X_test_text = X_humor_test.lemmatized_sentence.apply(remove_punctuation).str.strip().str.strip()\n",
    "X_test_text.reset_index(drop=True, inplace=True)\n",
    "X_test_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vocabolary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "leng = X_train_text.shape[0]\n",
    "for i in range(leng):\n",
    "    line = X_train_text.iloc[i].split()\n",
    "    all_words.extend(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>5027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>4282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you</td>\n",
       "      <td>2613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  counts\n",
       "0   the    5027\n",
       "1     a    4282\n",
       "2    to    3459\n",
       "3     i    2859\n",
       "4   you    2613"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.Series(all_words).value_counts().sort_values(ascending=False).rename('counts').reset_index()\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['string_count'] = word_counts['index'].apply(lambda l: len(str(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "      <th>string_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>3459</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>1986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>1858</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is</td>\n",
       "      <td>1557</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on</td>\n",
       "      <td>1522</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>fx</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>uv</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>oi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8277</th>\n",
       "      <td>ve</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11540</th>\n",
       "      <td>jr</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  counts  string_count\n",
       "2        to    3459             2\n",
       "6        of    1986             2\n",
       "7        in    1858             2\n",
       "8        is    1557             2\n",
       "9        on    1522             2\n",
       "...     ...     ...           ...\n",
       "8122     fx       1             2\n",
       "8141     uv       1             2\n",
       "8155     oi       1             2\n",
       "8277     ve       1             2\n",
       "11540    jr       1             2\n",
       "\n",
       "[186 rows x 3 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts[word_counts['string_count'] == 2].sort_values(by ='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "      <th>string_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>5027</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>4282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>3459</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you</td>\n",
       "      <td>2613</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>2420</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>1986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>1858</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is</td>\n",
       "      <td>1557</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on</td>\n",
       "      <td>1522</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>my</td>\n",
       "      <td>1505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "      <td>1428</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>me</td>\n",
       "      <td>1167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>for</td>\n",
       "      <td>1096</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>what</td>\n",
       "      <td>1022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>that</td>\n",
       "      <td>1022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  counts  string_count\n",
       "0    the    5027             3\n",
       "1      a    4282             1\n",
       "2     to    3459             2\n",
       "3      i    2859             1\n",
       "4    you    2613             3\n",
       "5    and    2420             3\n",
       "6     of    1986             2\n",
       "7     in    1858             2\n",
       "8     is    1557             2\n",
       "9     on    1522             2\n",
       "10    my    1505             2\n",
       "11    it    1428             2\n",
       "12    me    1167             2\n",
       "13   for    1096             3\n",
       "14  what    1022             4\n",
       "15  that    1022             4"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts[word_counts['counts'] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'a',\n",
       " 'to',\n",
       " 'i',\n",
       " 'you',\n",
       " 'and',\n",
       " 'of',\n",
       " 'in',\n",
       " 'is',\n",
       " 'on',\n",
       " 'my',\n",
       " 'it',\n",
       " 'me',\n",
       " 'for',\n",
       " 'what',\n",
       " 'that',\n",
       " 'with',\n",
       " 'do',\n",
       " 'hav',\n",
       " 'yo']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.nlargest(n=20, columns='counts')['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4767    1\n",
       "7230    0\n",
       "1752    0\n",
       "6930    1\n",
       "852     0\n",
       "       ..\n",
       "1519    0\n",
       "6190    1\n",
       "4371    0\n",
       "4647    0\n",
       "1161    0\n",
       "Name: is_humor, Length: 6400, dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_humor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Applying tf vectorizer (count vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to extract features from training data : 0.164561 seconds\n",
      "n_samples: 6400, n_features: 11634\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t = time()  # not compulsory\n",
    "\n",
    "# loading CountVectorizer\n",
    "tf_vectorizer = CountVectorizer() # or term frequency\n",
    "\n",
    "X_train_tf = tf_vectorizer.fit_transform(X_train_text)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming test data into tf-vectorized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to extract features from test data : 0.033356 seconds\n",
      "n_samples: 1600, n_features: 11634\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "X_test_tf = tf_vectorizer.transform(X_test_text)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.004s\n"
     ]
    }
   ],
   "source": [
    "# build naive bayes classification model\n",
    "t = time()\n",
    "\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, y_humor_train)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating accuracy and generating classification report from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_classifier.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.001s\n",
      "accuracy:   0.851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.87      0.73      0.80       630\n",
      "    Negative       0.84      0.93      0.88       970\n",
      "\n",
      "    accuracy                           0.85      1600\n",
      "   macro avg       0.86      0.83      0.84      1600\n",
      "weighted avg       0.85      0.85      0.85      1600\n",
      "\n",
      "confusion matrix:\n",
      "[[462 168]\n",
      " [ 70 900]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict the new document from the testing dataset\n",
    "t = time()\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "# compute the performance measures\n",
    "score1 = metrics.accuracy_score(y_humor_test, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_humor_test, y_pred,\n",
    "                                            target_names=['Positive', 'Negative']))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_humor_test, y_pred))\n",
    "\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
