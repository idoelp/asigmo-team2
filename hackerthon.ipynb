{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('~/Asigmo/AI Ethics/train_humour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       TENNESSEE: We're the best state. Nobody even c...\n",
       "1       A man inserted an advertisement in the classif...\n",
       "2       How many men does it take to open a can of bee...\n",
       "3       Told my mom I hit 1200 Twitter followers. She ...\n",
       "4       Roses are dead. Love is fake. Weddings are bas...\n",
       "                              ...                        \n",
       "7995    Lack of awareness of the pervasiveness of raci...\n",
       "7996      Why are aspirins white? Because they work sorry\n",
       "7997    Today, we Americans celebrate our independence...\n",
       "7998    How to keep the flies off the bride at an Ital...\n",
       "7999    \"Each ounce of sunflower seeds gives you 37% o...\n",
       "Name: text, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>7969</td>\n",
       "      <td>I saw a guy walking 4 dogs this morning and th...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>7703</td>\n",
       "      <td>BOOK: She gazed upon the sun-dappled lawn. ME:...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>6101</td>\n",
       "      <td>Pandas show little interest in company or frie...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>3987</td>\n",
       "      <td>The word 'infant' originates from the Latin wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>7389</td>\n",
       "      <td>\"The spaces between us, keep getting deeper.' ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>7190</td>\n",
       "      <td>Don't chase anyone. Don't beg anyone to stay. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>7839</td>\n",
       "      <td>Verily, the land does not make anyone holy; it...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>3647</td>\n",
       "      <td>Let's talk about sax, baby Let's talk about br...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>7772</td>\n",
       "      <td>My girlfriends threatened to leave me because ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>4974</td>\n",
       "      <td>I thought I won the argument with my wife as t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>1721</td>\n",
       "      <td>The most unrealistic part of action movies is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>621</td>\n",
       "      <td>la croix tastes like orange crush that gave up...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1657</td>\n",
       "      <td>60% of African American girls agree to giving ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>We think that mental health is important to mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>7401</td>\n",
       "      <td>\"Dad, on my way home from school I saw Santa b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>1421</td>\n",
       "      <td>Hopefully no one ever sees those shorts I was ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3070</td>\n",
       "      <td>Hummus as a whole contains plenty of Omega 3 f...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>4482</td>\n",
       "      <td>How do you excite an idiot? I'll tell you later.</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>6698</td>\n",
       "      <td>Mohammed spent a lot of time up mountains, sla...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7121</th>\n",
       "      <td>7122</td>\n",
       "      <td>So my girlfriend just told me that she needed ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "7968  7969  I saw a guy walking 4 dogs this morning and th...         1   \n",
       "7702  7703  BOOK: She gazed upon the sun-dappled lawn. ME:...         1   \n",
       "6100  6101  Pandas show little interest in company or frie...         0   \n",
       "3986  3987  The word 'infant' originates from the Latin wo...         0   \n",
       "7388  7389  \"The spaces between us, keep getting deeper.' ...         0   \n",
       "7189  7190  Don't chase anyone. Don't beg anyone to stay. ...         0   \n",
       "7838  7839  Verily, the land does not make anyone holy; it...         0   \n",
       "3646  3647  Let's talk about sax, baby Let's talk about br...         1   \n",
       "7771  7772  My girlfriends threatened to leave me because ...         1   \n",
       "4973  4974  I thought I won the argument with my wife as t...         1   \n",
       "1720  1721  The most unrealistic part of action movies is ...         1   \n",
       "620    621  la croix tastes like orange crush that gave up...         1   \n",
       "1656  1657  60% of African American girls agree to giving ...         1   \n",
       "1588  1589  We think that mental health is important to mi...         0   \n",
       "7400  7401  \"Dad, on my way home from school I saw Santa b...         1   \n",
       "1420  1421  Hopefully no one ever sees those shorts I was ...         1   \n",
       "3069  3070  Hummus as a whole contains plenty of Omega 3 f...         0   \n",
       "4481  4482   How do you excite an idiot? I'll tell you later.         1   \n",
       "6697  6698  Mohammed spent a lot of time up mountains, sla...         1   \n",
       "7121  7122  So my girlfriend just told me that she needed ...         1   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  \n",
       "7968          2.00                1.0            0.55  \n",
       "7702          1.76                1.0            0.00  \n",
       "6100           NaN                NaN            0.00  \n",
       "3986           NaN                NaN            0.10  \n",
       "7388           NaN                NaN            0.00  \n",
       "7189           NaN                NaN            0.00  \n",
       "7838           NaN                NaN            0.00  \n",
       "3646          2.38                0.0            0.00  \n",
       "7771          2.32                0.0            0.00  \n",
       "4973          2.60                1.0            0.00  \n",
       "1720          2.68                1.0            0.00  \n",
       "620           2.41                1.0            0.15  \n",
       "1656          1.11                0.0            4.05  \n",
       "1588           NaN                NaN            0.05  \n",
       "7400          0.89                0.0            3.25  \n",
       "1420          0.71                0.0            0.00  \n",
       "3069           NaN                NaN            0.00  \n",
       "4481          1.70                1.0            0.20  \n",
       "6697          2.37                1.0            2.95  \n",
       "7121          2.50                1.0            0.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/histograms.py:839: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/histograms.py:840: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  14.,   49.,  157.,  488., 1048., 1219., 1157.,  630.,  152.,\n",
       "          18.]),\n",
       " array([0.1 , 0.49, 0.88, 1.27, 1.66, 2.05, 2.44, 2.83, 3.22, 3.61, 4.  ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.humor_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3068.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        4932.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.is_humor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>'Trabajo,' the Spanish word for work, comes fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>I enrolled on some skill training and extra cu...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Men who ejaculated 21 times or more a month ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>I got REALLY angry today and it wasn't about n...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>A dog in Mexico named Frida saved the lives of...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>7990</td>\n",
       "      <td>Swimming provides mental health &amp; mediation. i...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>7993</td>\n",
       "      <td>Hey folx! All slots are full! Thank you so muc...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>7995</td>\n",
       "      <td>It's funny how you don't appreciate a thing un...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7996</td>\n",
       "      <td>Lack of awareness of the pervasiveness of raci...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>8000</td>\n",
       "      <td>\"Each ounce of sunflower seeds gives you 37% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3068 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "5        6  'Trabajo,' the Spanish word for work, comes fr...         0   \n",
       "6        7  I enrolled on some skill training and extra cu...         0   \n",
       "8        9  Men who ejaculated 21 times or more a month ha...         0   \n",
       "9       10  I got REALLY angry today and it wasn't about n...         0   \n",
       "10      11  A dog in Mexico named Frida saved the lives of...         0   \n",
       "...    ...                                                ...       ...   \n",
       "7989  7990  Swimming provides mental health & mediation. i...         0   \n",
       "7992  7993  Hey folx! All slots are full! Thank you so muc...         0   \n",
       "7994  7995  It's funny how you don't appreciate a thing un...         0   \n",
       "7995  7996  Lack of awareness of the pervasiveness of raci...         0   \n",
       "7999  8000  \"Each ounce of sunflower seeds gives you 37% o...         0   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  \n",
       "5              NaN                NaN            0.00  \n",
       "6              NaN                NaN            0.10  \n",
       "8              NaN                NaN            0.05  \n",
       "9              NaN                NaN            0.15  \n",
       "10             NaN                NaN            0.00  \n",
       "...            ...                ...             ...  \n",
       "7989           NaN                NaN            0.00  \n",
       "7992           NaN                NaN            0.00  \n",
       "7994           NaN                NaN            0.05  \n",
       "7995           NaN                NaN            0.25  \n",
       "7999           NaN                NaN            0.00  \n",
       "\n",
       "[3068 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.is_humor==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 8000 non-null   int64  \n",
      " 1   text               8000 non-null   object \n",
      " 2   is_humor           8000 non-null   int64  \n",
      " 3   humor_rating       4932 non-null   float64\n",
      " 4   humor_controversy  4932 non-null   float64\n",
      " 5   offense_rating     8000 non-null   float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 375.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.humor_rating.fillna(value = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>4932.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4000.50000</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>1.393614</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.585325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2309.54541</td>\n",
       "      <td>0.486269</td>\n",
       "      <td>1.185941</td>\n",
       "      <td>0.500051</td>\n",
       "      <td>0.979955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2000.75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4000.50000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6000.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     is_humor  humor_rating  humor_controversy  \\\n",
       "count  8000.00000  8000.000000   8000.000000        4932.000000   \n",
       "mean   4000.50000     0.616500      1.393614           0.499797   \n",
       "std    2309.54541     0.486269      1.185941           0.500051   \n",
       "min       1.00000     0.000000      0.000000           0.000000   \n",
       "25%    2000.75000     0.000000      0.000000           0.000000   \n",
       "50%    4000.50000     1.000000      1.760000           0.000000   \n",
       "75%    6000.25000     1.000000      2.420000           1.000000   \n",
       "max    8000.00000     1.000000      4.000000           1.000000   \n",
       "\n",
       "       offense_rating  \n",
       "count     8000.000000  \n",
       "mean         0.585325  \n",
       "std          0.979955  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.100000  \n",
       "75%          0.700000  \n",
       "max          4.850000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_humor  humor_rating  \\\n",
       "0  TENNESSEE: We're the best state. Nobody even c...         1          2.42   \n",
       "1  A man inserted an advertisement in the classif...         1          2.50   \n",
       "2  How many men does it take to open a can of bee...         1          1.95   \n",
       "3  Told my mom I hit 1200 Twitter followers. She ...         1          2.11   \n",
       "4  Roses are dead. Love is fake. Weddings are bas...         1          2.78   \n",
       "\n",
       "   offense_rating  \n",
       "0             0.2  \n",
       "1             1.1  \n",
       "2             2.4  \n",
       "3             0.0  \n",
       "4             0.1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.drop(columns=['humor_controversy','id'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_humor = df['is_humor']\n",
    "X_humor = df.drop(columns='is_humor')\n",
    "X_humor_train, X_humor_test, y_humor_train, y_humor_test = train_test_split(X_humor, y_humor, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>The CIA publicly acknowledged the existence of...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>Most people are shocked when they find out how...</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>Some men will never realize what a great woman...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>Colorism is alive and well in the black comm'y...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>Q: How do you know if a blonde  has been sendi...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>Instead of hanging useless wall art that says ...</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7843</th>\n",
       "      <td>Why don't bisexual people have any friends? Be...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>A toothbrush that is 6 feet within a toilet ca...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>Being in a relationship is a full time job. Da...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>Everybody keeps downvoting my racist jokes It'...</td>\n",
       "      <td>1.21</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  humor_rating  \\\n",
       "2884  The CIA publicly acknowledged the existence of...          0.00   \n",
       "1018  Most people are shocked when they find out how...          2.94   \n",
       "6594  Some men will never realize what a great woman...          0.00   \n",
       "7719  Colorism is alive and well in the black comm'y...          0.00   \n",
       "930   Q: How do you know if a blonde  has been sendi...          2.10   \n",
       "...                                                 ...           ...   \n",
       "1010  Instead of hanging useless wall art that says ...          2.33   \n",
       "7843  Why don't bisexual people have any friends? Be...          2.00   \n",
       "4292  A toothbrush that is 6 feet within a toilet ca...          0.00   \n",
       "2048  Being in a relationship is a full time job. Da...          0.00   \n",
       "2838  Everybody keeps downvoting my racist jokes It'...          1.21   \n",
       "\n",
       "      offense_rating  \n",
       "2884            0.00  \n",
       "1018            0.00  \n",
       "6594            0.00  \n",
       "7719            0.40  \n",
       "930             1.15  \n",
       "...              ...  \n",
       "1010            0.00  \n",
       "7843            0.85  \n",
       "4292            0.00  \n",
       "2048            0.15  \n",
       "2838            4.05  \n",
       "\n",
       "[6400 rows x 3 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_humor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_humor=X_humor_train.text.str.lower().str.strip().str.split()\n",
    "#data_humor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove sopwords and punctuations and digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/festo.owiny/Asigmo/hahackathon/pos_neg_list/stopwords.txt') as f:\n",
    "    stop_words = [line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       the cia publicly acknowledged the existence of...\n",
       "1       most people are shocked when they find out how...\n",
       "2       some men will never realize what a great woman...\n",
       "3       colorism is alive and well in the black commy ...\n",
       "4       q how do you know if a blonde has been sending...\n",
       "                              ...                        \n",
       "6395    instead of hanging useless wall art that says ...\n",
       "6396    why dont bisexual people have any friends beca...\n",
       "6397    a toothbrush that is feet within a toilet can ...\n",
       "6398    being in a relationship is a full time job dar...\n",
       "6399    everybody keeps downvoting my racist jokes its...\n",
       "Name: text, Length: 6400, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "exclude = set(string.punctuation + string.digits)\n",
    "\n",
    "def remove_punctuation(x):\n",
    "    \"\"\"\n",
    "    Helper function to remove punctuation from a string\n",
    "    x: any string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = ''.join(ch for ch in x if ch not in exclude)\n",
    "    except:\n",
    "        pass\n",
    "    res = re.sub(' +', ' ', x)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what if there was a fermented drink that wont ...\n",
       "1    back to the time you were lying next to me i l...\n",
       "2      what do japan and shaq have in common kobe beef\n",
       "3    in hawaii people are legally allowed to throw ...\n",
       "4    i just came out of my first relationship and i...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text = X_humor_train.text.apply(remove_punctuation).str.strip().str.lower()\n",
    "X_train_text.reset_index(drop=True, inplace=True)\n",
    "X_train_text.head()\n",
    "\n",
    "\n",
    "X_test_text = X_humor_test.text.apply(remove_punctuation).str.strip().str.lower()\n",
    "X_test_text.reset_index(drop=True, inplace=True)\n",
    "X_test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2884    the cia publicly acknowledged the existence of...\n",
       "1018    most people are shocked when they find out how...\n",
       "6594    some men will never realize what a great woman...\n",
       "7719    colorism is alive and well in the black commy ...\n",
       "930     q how do you know if a blonde has been sending...\n",
       "                              ...                        \n",
       "1010    instead of hanging useless wall art that says ...\n",
       "7843    why dont bisexual people have any friends beca...\n",
       "4292    a toothbrush that is feet within a toilet can ...\n",
       "2048    being in a relationship is a full time job dar...\n",
       "2838    everybody keeps downvoting my racist jokes its...\n",
       "Name: text, Length: 6400, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_humor_train.text.apply(remove_punctuation).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       tennessee were the best state nobody even come...\n",
       "1       a man inserted an advertisement in the classif...\n",
       "2       how many men does it take to open a can of bee...\n",
       "3       told my mom i hit  twitter followers she point...\n",
       "4       roses are dead love is fake weddings are basic...\n",
       "                              ...                        \n",
       "7995    lack of awareness of the pervasiveness of raci...\n",
       "7996       why are aspirins white because they work sorry\n",
       "7997    today we americans celebrate our independence ...\n",
       "7998    how to keep the flies off the bride at an ital...\n",
       "7999    each ounce of sunflower seeds gives you  of yo...\n",
       "Name: text, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.apply(remove_punctuation).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       the cia publicly acknowledged the existence of...\n",
       "1       most people are shocked when they find out how...\n",
       "2       some men will never realize what a great woman...\n",
       "3       colorism is alive and well in the black commy ...\n",
       "4       q how do you know if a blonde has been sending...\n",
       "                              ...                        \n",
       "6395    instead of hanging useless wall art that says ...\n",
       "6396    why dont bisexual people have any friends beca...\n",
       "6397    a toothbrush that is feet within a toilet can ...\n",
       "6398    being in a relationship is a full time job dar...\n",
       "6399    everybody keeps downvoting my racist jokes its...\n",
       "Name: text, Length: 6400, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords, Create vocabolary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "leng = X_train_text.shape[0]\n",
    "for i in range(leng):\n",
    "    line = X_train_text[i]\n",
    "    all_words.extend(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>5056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>4316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>2808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you</td>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  counts\n",
       "0   the    5056\n",
       "1     a    4316\n",
       "2    to    3412\n",
       "3     i    2808\n",
       "4   you    2587"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.Series(all_words).value_counts().sort_values(ascending=False).rename('counts').reset_index()\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'a',\n",
       " 'to',\n",
       " 'i',\n",
       " 'you',\n",
       " 'and',\n",
       " 'of',\n",
       " 'in',\n",
       " 'is',\n",
       " 'my',\n",
       " 'it',\n",
       " 'me',\n",
       " 'that',\n",
       " 'for',\n",
       " 'what',\n",
       " 'on',\n",
       " 'do',\n",
       " 'with',\n",
       " 'have',\n",
       " 'are']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.nlargest(n=20, columns='counts')['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6741    1\n",
       "758     1\n",
       "5463    1\n",
       "7202    1\n",
       "7743    1\n",
       "       ..\n",
       "304     0\n",
       "3925    1\n",
       "927     0\n",
       "1119    0\n",
       "4530    1\n",
       "Name: is_humor, Length: 6400, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_humor_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       term  occurrences\n",
      "0     about          440\n",
      "1     after          184\n",
      "2       all          437\n",
      "3      also           73\n",
      "4    always          152\n",
      "..      ...          ...\n",
      "227    year          100\n",
      "228   years          138\n",
      "229     you         2590\n",
      "230    your          773\n",
      "231   youre          239\n",
      "\n",
      "[232 rows x 2 columns]\n",
      "       term    weight\n",
      "0     about  0.018295\n",
      "1     after  0.008874\n",
      "2       all  0.017973\n",
      "3      also  0.004400\n",
      "4    always  0.008286\n",
      "..      ...       ...\n",
      "227    year  0.005772\n",
      "228   years  0.007114\n",
      "229     you  0.068648\n",
      "230    your  0.029194\n",
      "231   youre  0.011075\n",
      "\n",
      "[232 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>the</td>\n",
       "      <td>0.101595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>to</td>\n",
       "      <td>0.074233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>you</td>\n",
       "      <td>0.068648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>0.061697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>of</td>\n",
       "      <td>0.058592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>in</td>\n",
       "      <td>0.053942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>is</td>\n",
       "      <td>0.048573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>my</td>\n",
       "      <td>0.045760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>what</td>\n",
       "      <td>0.043798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>it</td>\n",
       "      <td>0.041229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>me</td>\n",
       "      <td>0.037822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>for</td>\n",
       "      <td>0.037159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>do</td>\n",
       "      <td>0.036597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>that</td>\n",
       "      <td>0.033477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>on</td>\n",
       "      <td>0.031359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>are</td>\n",
       "      <td>0.030092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>with</td>\n",
       "      <td>0.029446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>your</td>\n",
       "      <td>0.029194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>have</td>\n",
       "      <td>0.028572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>was</td>\n",
       "      <td>0.028145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     term    weight\n",
       "178   the  0.101595\n",
       "193    to  0.074233\n",
       "229   you  0.068648\n",
       "7     and  0.061697\n",
       "137    of  0.058592\n",
       "97     in  0.053942\n",
       "99     is  0.048573\n",
       "127    my  0.045760\n",
       "209  what  0.043798\n",
       "100    it  0.041229\n",
       "122    me  0.037822\n",
       "57    for  0.037159\n",
       "41     do  0.036597\n",
       "176  that  0.033477\n",
       "140    on  0.031359\n",
       "10    are  0.030092\n",
       "220  with  0.029446\n",
       "230  your  0.029194\n",
       "80   have  0.028572\n",
       "204   was  0.028145"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "#countVec = CountVectorizer(max_features= 5000, stop_words=stop_words, min_df=.01, max_df=.90)\n",
    "countVec = CountVectorizer(max_features= 5000, min_df=.01, max_df=.90)\n",
    "\n",
    "#%%\n",
    "#use CountVectorizer.fit(self, raw_documents[, y] to learn vocabulary dictionary of all tokens in raw documents\n",
    "#raw documents in this case will betweetsFrameWords[\"Text\"] (processed text)\n",
    "countVec.fit(X_train_text)\n",
    "#useful debug, get an idea of the item list you generated\n",
    "list(countVec.vocabulary_.items())\n",
    "\n",
    "#%%\n",
    "#convert to bag of words\n",
    "#sparse matrix representation? (README: could use an edit/explanation)\n",
    "countVec_count = countVec.transform(X_train_text)\n",
    "\n",
    "#%%\n",
    "#make array from number of occurrences\n",
    "occ = np.asarray(countVec_count.sum(axis=0)).ravel().tolist()\n",
    "\n",
    "#make a new data frame with columns term and occurrences, meaning word and number of occurences\n",
    "bowListFrame = pd.DataFrame({'term': countVec.get_feature_names(), 'occurrences': occ})\n",
    "print(bowListFrame)\n",
    "\n",
    "#sort in order of number of word occurences, most->least. if you leave of ascending flag should default ASC\n",
    "bowListFrame.sort_values(by='occurrences', ascending=False).head(60)\n",
    "\n",
    "#%%\n",
    "#now, convert to a more useful ranking system, tf-idf weights\n",
    "#TfidfTransformer: scale raw word counts to a weighted ranking using the\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "humourTransformer = TfidfTransformer()\n",
    "\n",
    "#initial fit representation using transformer object\n",
    "humourWeights = humourTransformer.fit_transform(countVec_count)\n",
    "\n",
    "#follow similar process to making new data frame with word occurrences, but with term weights\n",
    "humourWeightsFin = np.asarray(humourWeights.mean(axis=0)).ravel().tolist()\n",
    "\n",
    "#now that we've done Tfid, make a dataframe with weights and names\n",
    "humourWeightFrame = pd.DataFrame({'term': countVec.get_feature_names(), 'weight': humourWeightsFin})\n",
    "print(humourWeightFrame)\n",
    "humourWeightFrame.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'texthero'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-577e446af87b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtexthero\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'texthero'"
     ]
    }
   ],
   "source": [
    "import texthero as hero\n",
    "hero.tfidf(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-1f4844c0697c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_humor_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \"\"\"\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=data_humor_stop_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_CountVectorizer = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB()), ]) #Count\n",
    "text_clf_TF_IDF = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB()), ]) #TFiDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_CountVectorizer.fit(data_humor_stop_text.astype('U'), y_humor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_TF_IDF.fit(data_humor_stop_text.astype('U'), y_humor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_CountVectorizer = text_clf_CountVectorizer.predict(X_humor_test.astype('U'))\n",
    "predicted_TF_IDF = text_clf_TF_IDF.predict(X_humor_test.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1600, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-39a4e86ce793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_humor_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_CountVectorizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_humor_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_TF_IDF\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1600, 3]"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_humor_test, predicted_CountVectorizer) )\n",
    "print(metrics.accuracy_score(y_humor_test, predicted_TF_IDF) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Applying tf vectorizer (count vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to extract features from training data : 0.145129 seconds\n",
      "n_samples: 6400, n_features: 13093\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t = time()  # not compulsory\n",
    "\n",
    "# loading CountVectorizer\n",
    "tf_vectorizer = CountVectorizer() # or term frequency\n",
    "\n",
    "X_train_tf = tf_vectorizer.fit_transform(X_train_text)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming test data into tf-vectorized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to extract features from test data : 0.028275 seconds\n",
      "n_samples: 1600, n_features: 13093\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "X_test_tf = tf_vectorizer.transform(X_test_text)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.011s\n"
     ]
    }
   ],
   "source": [
    "# build naive bayes classification model\n",
    "t = time()\n",
    "\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, y_humor_train)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating accuracy and generating classification report from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_classifier.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.002s\n",
      "accuracy:   0.839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.84      0.74      0.79       637\n",
      "    Negative       0.84      0.90      0.87       963\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.84      0.82      0.83      1600\n",
      "weighted avg       0.84      0.84      0.84      1600\n",
      "\n",
      "confusion matrix:\n",
      "[[472 165]\n",
      " [ 93 870]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict the new document from the testing dataset\n",
    "t = time()\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "# compute the performance measures\n",
    "score1 = metrics.accuracy_score(y_humor_test, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_humor_test, y_pred,\n",
    "                                            target_names=['Positive', 'Negative']))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_humor_test, y_pred))\n",
    "\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.003s\n",
      "accuracy:   0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.95      0.87      0.91      2431\n",
      "    Negative       0.93      0.97      0.95      3969\n",
      "\n",
      "    accuracy                           0.93      6400\n",
      "   macro avg       0.94      0.92      0.93      6400\n",
      "weighted avg       0.93      0.93      0.93      6400\n",
      "\n",
      "confusion matrix:\n",
      "[[2125  306]\n",
      " [ 115 3854]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict the new document from the testing dataset\n",
    "t = time()\n",
    "y_pred = naive_bayes_classifier.predict(X_train_tf)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "# compute the performance measures\n",
    "score1 = metrics.accuracy_score(y_humor_train, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_humor_train, y_pred,\n",
    "                                            target_names=['Positive', 'Negative']))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_humor_train, y_pred))\n",
    "\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
